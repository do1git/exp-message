# 패치노트 - 2026-01-06

## 목표했던 내용 1

- 인프라 디렉토리 구조 설계 및 정리

## 변경사항 1

- 인프라 디렉토리 구조 설계 문서 작성 (`01-infrastructure/README.md`)
  - 서비스별 독립적인 인프라 리소스 디렉토리 구조 정의
  - 서비스 간 통신을 위한 공유 리소스 디렉토리 구조 정의
  - 배포 및 오케스트레이션 설정 디렉토리 구조 정의
  - 모니터링 설정 디렉토리 구조 정의

## 목표했던 내용 2

- 인프라 구조 설계 시 고민했던 주요 사항 정리

## 변경사항 2

- 인프라 구조 설계 고민 사항 문서 작성 (상세 내용은 아래 참고)

---

## Infrastructure 구조 설계

## 개요

인프라 디렉토리 구조를 설계하면서 고민했던 내용들을 정리한 문서입니다.

## 최종 구조

```text
01-infrastructure/
├── 01-service-resources/      # 서비스별 독립적인 인프라 리소스
│   ├── 01-api-gateway/
│   ├── 02-user-service/
│   ├── 03-chat-room-service/
│   ├── 04-message-service/
│   ├── 05-search-service/
│   ├── 06-notification-service/
│   └── 07-websocket-service/
├── 02-inter-service-resources/ # 서비스 간 통신을 위한 공유 리소스
│   └── kafka/
├── 03-deployment/             # 배포 및 오케스트레이션 설정
│   ├── docker-compose/
│   └── k8s/
└── 04-monitoring/             # 모니터링 설정
```

## 주요 고민 사항

### 1. Service Resources 구조

**초기 고민:**

- `01-service-resources/databases/` 형태로 모든 데이터베이스를 한 곳에 관리할지 고민
- 서비스별로 분리할지 고민

**결정:**

- 각 서비스별로 디렉토리를 구성 (`01-service-resources/{service-name}/`)
- Database per Service 패턴에 따라 각 서비스의 데이터베이스는 해당 서비스 디렉토리에 포함
- 각 서비스 디렉토리 내부 구조는 필요에 따라 서비스별로 정의 (유연성 확보)

**이유:**

- 서비스 독립성 확보
- 서비스별 인프라 리소스를 한 곳에서 관리 가능
- 확장성과 유지보수성 향상

### 2. Inter-Service Resources 범위

**초기 고민:**

- Redis를 `inter-service-resources`에 포함할지 고민
- Database per Service 패턴에서 Redis도 포함되는지 고민

**결정:**

- `inter-service-resources`는 서비스 간 통신(Pub/Sub)에만 사용
- Kafka만 포함
- Redis는 필요 시 각 서비스의 `service-resources`에 포함

**이유:**

- Database per Service 패턴에 따라 각 서비스가 독립적으로 사용하는 리소스는 서비스별로 관리
- 서비스 간 통신은 Kafka로 충분
- Redis는 캐싱, 세션 관리 등 서비스별 용도로 사용될 가능성이 높음

### 3. Outbox 패턴

**고민:**

- Outbox 패턴을 위한 별도의 MySQL 인스턴스가 필요한지 고민

**결정:**

- 별도의 MySQL 인스턴스 불필요
- 각 서비스의 데이터베이스 내에 outbox 테이블 포함
- CDC(Debezium/Kafka Connect) 또는 폴링 방식으로 처리

**이유:**

- 일반적인 Outbox 패턴 구현 방식
- 각 서비스의 트랜잭션과 함께 outbox에 이벤트 기록
- 별도 인스턴스는 중앙 집중식 아키텍처나 특수한 경우에만 필요

### 4. Kafka 클러스터 분리

**고민:**

- 전체 서비스에서 하나의 Kafka 클러스터를 공유할지
- 클러스터를 분리할지 고민

**결정:**

- 하나의 Kafka 클러스터를 여러 서비스가 공유
- Topic으로 논리적 분리

**이유:**

- 일반적인 사용 패턴
- 관리와 운영이 단순함
- 비용 효율적
- 필요 시 나중에 분리 가능 (환경별, 용도별, 보안 요구사항 등)

### 5. Deployment 도구 선택

**고민:**

- Kubernetes 배포를 위한 도구 선택
- Helm vs Kustomize vs ArgoCD vs Helmfile 등

**고려 사항:**

- 7개의 마이크로서비스로 템플릿화 필요
- 환경별 배포 관리 필요
- 유지보수와 확장성 고려

**결정:**

- Helm 또는 Helmfile 사용 검토 중
- GitOps 자동화가 필요하면 ArgoCD 추가 고려

**이유:**

- Helm: 널리 사용, 패키징/재사용성, 커뮤니티 지원
- Helmfile: Helm을 더 쉽게 사용, 여러 차트 관리, 환경별 values 관리
- ArgoCD: GitOps 자동화, UI 제공, 멀티 클러스터 관리

### 6. 서비스 디렉토리 내부 구조

**고민:**

- 각 서비스 디렉토리 내부 구조를 자세히 정의할지 고민

**결정:**

- 각 서비스 디렉토리 내부 구조는 필요에 따라 서비스별로 정의
- 미리 자세히 정하지 않고, 필요할 때마다 선언해서 정의

**이유:**

- 유연성 확보
- 서비스별 특성에 맞는 구조 구성 가능
- 과도한 구조 정의 방지

## 설계 원칙

1. **서비스별 리소스 분리**: 각 서비스가 독립적으로 사용하는 리소스는 서비스별 디렉토리로 관리

2. **서비스 간 통신 리소스 분리**: 서비스 간 Pub/Sub 통신을 위한 공유 인프라는 별도로 관리

3. **배포 스크립트 통합**: 배포 관련 설정을 한 곳에서 관리

4. **모니터링 독립**: 모니터링 설정을 별도로 분리하여 관리

5. **유연성 확보**: 필요에 따라 구조를 확장하고 변경할 수 있도록 설계
